{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "premium-spending",
   "metadata": {},
   "source": [
    "# Minimum imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-steam",
   "metadata": {},
   "source": [
    "### Dependencies & utiliy methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sorted-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gb\n",
    "from itertools import combinations, product\n",
    "from math import floor\n",
    "from functools import partial\n",
    "\n",
    "# other solver engines\n",
    "from ortools.graph import pywrapgraph\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "creative-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples from the control samples are indexed from 0 to n_prime\n",
    "def extract_n_prime(L_prime, k):\n",
    "    M = 0\n",
    "    for i in range(k[0]):\n",
    "        if len(L_prime[0][i]) > 0:\n",
    "            M = max(M, np.max(L_prime[0][i]))\n",
    "    return int(M) + 1\n",
    "\n",
    "\n",
    "# number of treatment samples (and also cardinality of S)\n",
    "def extract_n(l):\n",
    "    return int(sum(l[0]))\n",
    "\n",
    "\n",
    "def extract_k(l):\n",
    "    return list(map(len, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-separate",
   "metadata": {},
   "source": [
    "### Brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sought-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_imbalance(map_L_prime_to_value, S, l):\n",
    "    s = 0\n",
    "    for p in range(P):\n",
    "        S = list(S)\n",
    "        values, counts = np.unique(map_L_prime_to_value[p][S], return_counts=True)\n",
    "        # we might be missing some values in values\n",
    "        full_counts = np.zeros(len(l[p]), dtype=int)\n",
    "        full_counts[values] = counts\n",
    "        s += np.sum(np.abs(full_counts - l[p]))\n",
    "    return s\n",
    "\n",
    "\n",
    "def brute_force(l, L_prime):\n",
    "    k = extract_k(l)\n",
    "    n_prime = extract_n_prime(L_prime, k)\n",
    "    n = extract_n(l)\n",
    "\n",
    "    z = np.arange(n_prime)\n",
    "\n",
    "    P = len(k)\n",
    "\n",
    "    map_L_prime_to_value = []\n",
    "    for p in range(P):\n",
    "        ls = np.empty(n_prime, dtype=int)\n",
    "        for i in range(k[p]):\n",
    "            ls[L_prime[p][i]] = i\n",
    "        map_L_prime_to_value.append(ls)\n",
    "\n",
    "    m = 10000000\n",
    "    S_m = None\n",
    "    for S in combinations(z, n):\n",
    "        mi = compute_imbalance(map_L_prime_to_value, S, l)\n",
    "        if mi < m:\n",
    "            m = mi\n",
    "            S_m = [S]\n",
    "        elif mi == m:\n",
    "            S_m.append(S)\n",
    "    return S_m, m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-frost",
   "metadata": {},
   "source": [
    "### Linear programming formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disabled-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each k[i] consecutive rows of A contain 1 in the j-th\n",
    "# column if for the (i+1)-th covariate we have that\n",
    "# z[j] belongs to the k-th bucket of the covariate i,\n",
    "# where k is the offset from k[i]+sum(k[:i])\n",
    "def compute_A(L_prime, k, n_prime):\n",
    "    A = np.zeros((sum(k), n_prime), dtype=int)\n",
    "    current_row = 0\n",
    "    for p in range(P):\n",
    "        Lp_prime = L_prime[p]\n",
    "        for i in range(k[p]):\n",
    "            A[current_row, Lp_prime[i]] = 1\n",
    "            current_row += 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def min_imbalance_solver(l, L_prime, verbose=False):\n",
    "    min_imbalance = gb.Model()\n",
    "    min_imbalance.modelSense = gb.GRB.MINIMIZE\n",
    "    min_imbalance.setParam(\"outputFlag\", 0)\n",
    "\n",
    "    n = extract_n(l)\n",
    "    k = extract_k(l)\n",
    "    P = len(k)\n",
    "    l = np.array(np.concatenate(l))\n",
    "    n_prime = extract_n_prime(L_prime, k)\n",
    "\n",
    "    # 1e\n",
    "    z = min_imbalance.addMVar(n_prime, vtype=gb.GRB.BINARY)\n",
    "    y = min_imbalance.addMVar(sum(k))\n",
    "\n",
    "    A = compute_A(L_prime, k, n_prime)\n",
    "\n",
    "    # 1b\n",
    "    min_imbalance.addConstr(A @ z - l <= y)\n",
    "    # 1c\n",
    "    min_imbalance.addConstr(l - A @ z <= y)\n",
    "    # 1d\n",
    "    min_imbalance.addConstr(gb.quicksum(z) == n)\n",
    "\n",
    "    # 1a\n",
    "    min_imbalance.setObjective(gb.quicksum(y))\n",
    "\n",
    "    min_imbalance.optimize()\n",
    "\n",
    "    if verbose:\n",
    "        if min_imbalance.status == 2:\n",
    "            print(\"OK\")\n",
    "        else:\n",
    "            print(\"Bad things happened\")\n",
    "    return z.x, sum(y.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-florence",
   "metadata": {},
   "source": [
    "### Alternative linear programming formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exterior-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_imbalance_solver_alt(l, L_prime, verbose=False):\n",
    "    min_imbalance = gb.Model()\n",
    "    min_imbalance.modelSense = gb.GRB.MINIMIZE\n",
    "    min_imbalance.setParam(\"outputFlag\", 0)\n",
    "\n",
    "    n = extract_n(l)\n",
    "    k = extract_k(l)\n",
    "    P = len(k)\n",
    "    l = np.array(np.concatenate(l))\n",
    "    n_prime = extract_n_prime(L_prime, k)\n",
    "\n",
    "    assert P == 2\n",
    "\n",
    "    # 2f\n",
    "    z = min_imbalance.addMVar(n_prime, vtype=gb.GRB.BINARY)\n",
    "    # 2e\n",
    "    e = min_imbalance.addMVar(sum(k), lb=0.0)\n",
    "    d = min_imbalance.addMVar(sum(k), lb=0.0)\n",
    "\n",
    "    A = compute_A(L_prime, k, n_prime)\n",
    "\n",
    "    for p in range(2):\n",
    "        # smallest index for the covariate p\n",
    "        bottom_index = sum(k[:p])\n",
    "        # biggest index for the covariate p\n",
    "        top_index = k[p] + bottom_index\n",
    "\n",
    "        sl = slice(bottom_index, top_index)\n",
    "        # 2b/2c\n",
    "        min_imbalance.addConstr(A[sl] @ z + d[sl] - e[sl] == l[sl])\n",
    "\n",
    "    # 2d\n",
    "    min_imbalance.addConstr(gb.quicksum(e[: k[0]]) - gb.quicksum(d[: k[0]]) == 0)\n",
    "\n",
    "    # 2a\n",
    "    min_imbalance.setObjective(gb.quicksum(e) + gb.quicksum(d))\n",
    "\n",
    "    min_imbalance.optimize()\n",
    "\n",
    "    if verbose:\n",
    "        if min_imbalance.status == 2:\n",
    "            print(\"OK\")\n",
    "        else:\n",
    "            print(\"Bad things happened\")\n",
    "    return z.x, sum(e.x) + sum(d.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-morris",
   "metadata": {},
   "source": [
    "### Minimum cost network flow (linear programming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blind-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_U(A, k):\n",
    "    U = np.empty((k[0], k[1]), dtype=int)\n",
    "\n",
    "    A1 = A[: k[0]] > 0\n",
    "    A2 = A[k[0] :] > 0\n",
    "\n",
    "    return np.count_nonzero(np.logical_and(A1[:, None], A2[None]), axis=-1)\n",
    "\n",
    "\n",
    "def X_to_Z(A, k, X):\n",
    "    U = np.empty((k[0], k[1]), dtype=int)\n",
    "\n",
    "    A1 = A[: k[0]] > 0\n",
    "    A2 = A[k[0] :] > 0\n",
    "\n",
    "    B = np.logical_and(A1[:, None], A2[None])\n",
    "\n",
    "    z = np.zeros(B.shape[2])\n",
    "    for i1 in range(B.shape[0]):\n",
    "        for i2 in range(B.shape[1]):\n",
    "            # i1 \\cap i2\n",
    "            intersection = int(X[i1 * k[1] + i2])\n",
    "            # we take the first intersection values in the intersection\n",
    "            take = np.where(B[i1, i2])[0][:intersection]\n",
    "            z[take] = 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def min_imbalance_solver_mcnf(l, L_prime, verbose=False):\n",
    "    min_imbalance = gb.Model()\n",
    "    min_imbalance.modelSense = gb.GRB.MINIMIZE\n",
    "    min_imbalance.setParam(\"outputFlag\", 0)\n",
    "\n",
    "    n = extract_n(l)\n",
    "    k = extract_k(l)\n",
    "    P = len(k)\n",
    "    l = np.array(np.concatenate(l))\n",
    "    n_prime = extract_n_prime(L_prime, k)\n",
    "\n",
    "    assert P == 2\n",
    "\n",
    "    A = compute_A(L_prime, k, n_prime)\n",
    "    U = compute_U(A, k)\n",
    "\n",
    "    # 3g (i2 changes faster than i1)\n",
    "    x = min_imbalance.addMVar(U.shape[0] * U.shape[1], lb=0.0, ub=U.flatten(order=\"C\"))\n",
    "    # 3f\n",
    "    e = min_imbalance.addMVar(sum(k), lb=0.0)\n",
    "    d = min_imbalance.addMVar(sum(k), lb=0.0)\n",
    "\n",
    "    for p in range(2):\n",
    "        # 3b\n",
    "        for i1 in range(k[0]):\n",
    "            x_i1 = gb.quicksum(x[k[1] * i1 : k[1] * (i1 + 1)])\n",
    "            min_imbalance.addConstr(x_i1 + d[i1] - e[i1] == l[i1])\n",
    "\n",
    "        # 3c\n",
    "        for i2 in range(k[1]):\n",
    "            x_i2 = gb.quicksum(x[i2 :: k[1]])\n",
    "            min_imbalance.addConstr(\n",
    "                -x_i2 - d[k[0] + i2] + e[k[0] + i2] == -l[k[0] + i2]\n",
    "            )\n",
    "\n",
    "        # 3d\n",
    "        min_imbalance.addConstr(gb.quicksum(e[: k[0]]) - gb.quicksum(d[: k[0]]) == 0)\n",
    "\n",
    "        # 3e\n",
    "        min_imbalance.addConstr(gb.quicksum(e[k[0] :]) - gb.quicksum(d[k[0] :]) == 0)\n",
    "\n",
    "    # 3a\n",
    "    min_imbalance.setObjective(gb.quicksum(e) + gb.quicksum(d))\n",
    "\n",
    "    min_imbalance.optimize()\n",
    "\n",
    "    if verbose:\n",
    "        if min_imbalance.status == 2:\n",
    "            print(\"OK\")\n",
    "        else:\n",
    "            print(\"Bad things happened\")\n",
    "    return X_to_Z(A, k, x.x), sum(e.x) + sum(d.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-leadership",
   "metadata": {},
   "source": [
    "### Minimum cost network flow (NetworkX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "severe-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity = 100000000\n",
    "\n",
    "# we set all data explicitly because this will be used by another solver\n",
    "def min_imbalance_network(l, L_prime):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    G.add_node(0, demand=0)\n",
    "    G.add_node(1, demand=0)\n",
    "\n",
    "    n = extract_n(l)\n",
    "    k = extract_k(l)\n",
    "    P = len(k)\n",
    "    assert P == 2\n",
    "\n",
    "    for i in range(k[0]):\n",
    "        G.add_node((0, i), demand=-l[0][i])\n",
    "    for i in range(k[1]):\n",
    "        G.add_node((1, i), demand=l[1][i])\n",
    "\n",
    "    # excess\n",
    "    for i in range(k[0]):\n",
    "        G.add_edge(0, (0, i), weight=1, capacity=infinity)\n",
    "    for i in range(k[1]):\n",
    "        G.add_edge((1, i), 1, weight=1, capacity=infinity)\n",
    "\n",
    "    # deficit\n",
    "    for i in range(k[0]):\n",
    "        G.add_edge((0, i), 0, weight=1, capacity=infinity)\n",
    "    for i in range(k[1]):\n",
    "        G.add_edge(1, (1, i), weight=1, capacity=infinity)\n",
    "\n",
    "    # x_{i1,i2}\n",
    "    l = np.array(np.concatenate(l))\n",
    "    n_prime = extract_n_prime(L_prime, k)\n",
    "    A = compute_A(L_prime, k, n_prime)\n",
    "    U = compute_U(A, k)\n",
    "\n",
    "    for i1 in range(k[0]):\n",
    "        for i2 in range(k[1]):\n",
    "            if U[i1, i2] > 0:\n",
    "                G.add_edge((0, i1), (1, i2), capacity=U[i1, i2], weight=0)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def min_imbalance_networkx_extract_result(dc):\n",
    "    s = 0\n",
    "    for source, dests in dc.items():\n",
    "        # we are interested in counting only d and e\n",
    "        for dest, value in dests.items():\n",
    "            if not isinstance(dest, tuple) or not isinstance(source, tuple):\n",
    "                s += value\n",
    "    return s\n",
    "\n",
    "\n",
    "def min_imbalance_solver_networkx(l, L_prime, verbose=False):\n",
    "    net = min_imbalance_network(l, L_prime)\n",
    "\n",
    "    if verbose:\n",
    "        for node in net.nodes(data=True):\n",
    "            print(\"- o {}\".format(node))\n",
    "        for edg in net.edges(data=True):\n",
    "            print(\"- > {}\".format(edg))\n",
    "\n",
    "    dc = nx.min_cost_flow(net)\n",
    "    return min_imbalance_networkx_extract_result(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-penetration",
   "metadata": {},
   "source": [
    "### Minimum cost network flow (Google OR-Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chinese-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_networkx_to_ortools(net, ortools_flow_obj):\n",
    "    mapping = {}\n",
    "    i = 0\n",
    "\n",
    "    # weight and capacity\n",
    "    for source, dest, data in net.edges(data=True):\n",
    "        if source not in mapping:\n",
    "            mapping[source] = i\n",
    "            i += 1\n",
    "        if dest not in mapping:\n",
    "            mapping[dest] = i\n",
    "            i += 1\n",
    "\n",
    "        assert int(data[\"capacity\"]) == data[\"capacity\"]\n",
    "        assert int(data[\"weight\"]) == data[\"weight\"]\n",
    "\n",
    "        arc = ortools_flow_obj.AddArcWithCapacityAndUnitCost(\n",
    "            mapping[source], mapping[dest], int(data[\"capacity\"]), int(data[\"weight\"])\n",
    "        )\n",
    "\n",
    "    for node, data in net.nodes(data=True):\n",
    "        assert int(data[\"demand\"]) == data[\"demand\"]\n",
    "        ortools_flow_obj.SetNodeSupply(mapping[node], -int(data[\"demand\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floppy-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_imbalance_solver_google(l, L_prime):\n",
    "    G = min_imbalance_network(l, L_prime)\n",
    "\n",
    "    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
    "    convert_networkx_to_ortools(G, min_cost_flow)\n",
    "\n",
    "    status = min_cost_flow.Solve()\n",
    "    if status == min_cost_flow.INFEASIBLE:\n",
    "        print(\"Infeasible\")\n",
    "    elif status == min_cost_flow.UNBALANCED:\n",
    "        print(\"Unbalanced\")\n",
    "    else:\n",
    "        return min_cost_flow.OptimalCost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-embassy",
   "metadata": {},
   "source": [
    "### Minimum network flow with $q \\neq n$ (NetworkX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspected-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zero_cost_arc_capacity(li, q, n):\n",
    "    return floor(q / n * li)\n",
    "\n",
    "\n",
    "def compute_one_capacity_arc_weight(li, q, n):\n",
    "    t = q / n * li\n",
    "    return 1 - (t - floor(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "under-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_search(ls, left, right, condition):\n",
    "    if left == right:\n",
    "        return left\n",
    "\n",
    "    m = floor((left + right) / 2)\n",
    "    v = condition(ls[m])\n",
    "    if v == 0:\n",
    "        return m\n",
    "    if v < 0:\n",
    "        return binary_search(ls, m + 1, right, condition)\n",
    "    return binary_search(ls, left, m, condition)\n",
    "\n",
    "\n",
    "def find_5(x):\n",
    "    if x == 5:\n",
    "        return 0\n",
    "    if x < 5:\n",
    "        return -1\n",
    "    return 1\n",
    "\n",
    "\n",
    "l = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "l[binary_search(l, 0, 6, find_5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "historic-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(power, t):\n",
    "    k = power * t\n",
    "    if k / 10 == int(k / 10):\n",
    "        return 1\n",
    "    if k == int(k):\n",
    "        return 0\n",
    "    return -1\n",
    "\n",
    "\n",
    "# find the smallest power of 10 which should be used to multiply in order to obtain\n",
    "# integer weights for all the arcs\n",
    "def minimum_scaling(ls, max_power=10):\n",
    "    powers = np.power(10, np.arange(max_power + 1))\n",
    "\n",
    "    top = 0\n",
    "    for t in ls:\n",
    "        if t == int(t):\n",
    "            continue\n",
    "        cnd = partial(condition, t=t)\n",
    "        tp = binary_search(powers, 0, len(powers), cnd)\n",
    "        if tp >= max_power:\n",
    "            print(\"Ceiling reached with {}\".format(t))\n",
    "            tp = max_power - 1\n",
    "        top = max(top, tp)\n",
    "    return top\n",
    "\n",
    "\n",
    "# we set all data explicitly because this will be used by another solver.\n",
    "# max_power is the maximum exponent such that 10^max_power is an allowed multiplier to\n",
    "# scale weights in the graph in order to have integer weights.\n",
    "# this function returns the graph, and the multiplier used for the weights\n",
    "def general_min_imbalance_network(l, L_prime, q, max_power):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    G.add_node(0, demand=-q)\n",
    "    G.add_node(1, demand=q)\n",
    "\n",
    "    n = extract_n(l)\n",
    "    k = extract_k(l)\n",
    "    P = len(k)\n",
    "    assert P == 2\n",
    "\n",
    "    all_weights = [q / n] + [\n",
    "        compute_one_capacity_arc_weight(l[p][i], q, n) * 2 / q\n",
    "        for p in range(P)\n",
    "        for i in range(k[p])\n",
    "    ]\n",
    "    powers = np.power(10, np.arange(max_power + 1))\n",
    "    top = minimum_scaling(all_weights, max_power)\n",
    "\n",
    "    for i in range(k[0]):\n",
    "        G.add_node((0, i), demand=0)\n",
    "    for i in range(k[1]):\n",
    "        G.add_node((1, i), demand=0)\n",
    "\n",
    "    # cost zero\n",
    "    for i in range(k[0]):\n",
    "        G.add_edge(\n",
    "            0,\n",
    "            (0, i),\n",
    "            weight=1,\n",
    "            capacity=compute_zero_cost_arc_capacity(l[0][i], q, n) * powers[top],\n",
    "        )\n",
    "    for i in range(k[1]):\n",
    "        G.add_edge(\n",
    "            (1, i),\n",
    "            1,\n",
    "            weight=1,\n",
    "            capacity=compute_zero_cost_arc_capacity(l[1][i], q, n) * powers[top],\n",
    "        )\n",
    "\n",
    "    # capacity one\n",
    "    for i in range(k[0]):\n",
    "        G.add_edge(\n",
    "            0,\n",
    "            (0, i),\n",
    "            weight=compute_one_capacity_arc_weight(l[0][i], q, n) * 2 / q * powers[top],\n",
    "            capacity=1,\n",
    "        )\n",
    "    for i in range(k[1]):\n",
    "        G.add_edge(\n",
    "            (1, i),\n",
    "            1,\n",
    "            weight=compute_one_capacity_arc_weight(l[1][i], q, n) * 2 / q * powers[top],\n",
    "            capacity=1,\n",
    "        )\n",
    "\n",
    "    # capacity infinity\n",
    "    for i in range(k[0]):\n",
    "        G.add_edge(0, (0, i), weight=2 / q * powers[top], capacity=infinity)\n",
    "    for i in range(k[1]):\n",
    "        G.add_edge((1, i), 1, weight=2 / q * powers[top], capacity=infinity)\n",
    "\n",
    "    # x_{i1,i2}\n",
    "    l = np.array(np.concatenate(l))\n",
    "    n_prime = extract_n_prime(L_prime, k)\n",
    "    A = compute_A(L_prime, k, n_prime)\n",
    "    U = compute_U(A, k)\n",
    "\n",
    "    for i1 in range(k[0]):\n",
    "        for i2 in range(k[1]):\n",
    "            if U[i1, i2] > 0:\n",
    "                G.add_edge((0, i1), (1, i2), capacity=U[i1, i2], weight=0)\n",
    "\n",
    "    return G, powers[top]\n",
    "\n",
    "\n",
    "def general_min_imbalance_networkx_extract_result(G, dc):\n",
    "    s = 0\n",
    "    for source, dests in dc.items():\n",
    "        # we are interested in counting only d and e\n",
    "        for dest, value in dests.items():\n",
    "            if not isinstance(dest, tuple) or not isinstance(source, tuple):\n",
    "                s += value * G.get_edge_data(source, dest)[\"weight\"]\n",
    "    return s\n",
    "\n",
    "\n",
    "def general_min_imbalance_solver_networkx(l, L_prime, q, verbose=False, max_power=10):\n",
    "    net, scale = general_min_imbalance_network(l, L_prime, q, max_power=max_power)\n",
    "\n",
    "    if verbose:\n",
    "        for node in net.nodes(data=True):\n",
    "            print(\"- o {}\".format(node))\n",
    "        for edg in net.edges(data=True):\n",
    "            print(\"- > {}\".format(edg))\n",
    "\n",
    "    dc = nx.min_cost_flow(net)\n",
    "    return general_min_imbalance_networkx_extract_result(net, dc) / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-monday",
   "metadata": {},
   "source": [
    "### Minimum network flow with $q \\neq n$ (Google OR-Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pursuant-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_min_imbalance_solver_google(l, L_prime, q, max_power=10):\n",
    "    G, scale = general_min_imbalance_network(l, L_prime, q, max_power=max_power)\n",
    "\n",
    "    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n",
    "    convert_networkx_to_ortools(G, min_cost_flow)\n",
    "\n",
    "    status = min_cost_flow.Solve()\n",
    "    if status == min_cost_flow.INFEASIBLE:\n",
    "        print(\"Infeasible\")\n",
    "    elif status == min_cost_flow.UNBALANCED:\n",
    "        print(\"Unbalanced\")\n",
    "    else:\n",
    "        return min_cost_flow.OptimalCost() / (scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-century",
   "metadata": {},
   "source": [
    "## Experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-student",
   "metadata": {},
   "source": [
    "### Random dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affecting-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(a):\n",
    "    a = a[a[:, 0].argsort()]\n",
    "    return np.split(a[:, 1], np.unique(a[:, 0], return_index=True)[1][1:])\n",
    "\n",
    "\n",
    "def random_Lprime(P, n_prime, k):\n",
    "    L_prime = [None for p in range(P)]\n",
    "    for p in range(P):\n",
    "        # randomly select a level for each control value\n",
    "        choice = np.random.choice(np.arange(k[p]), size=n_prime)\n",
    "        indexed_choices = np.hstack([choice[:, None], np.arange(n_prime)[:, None]])\n",
    "        gb = group_by(indexed_choices)\n",
    "\n",
    "        un = np.unique(choice)\n",
    "        i = 0\n",
    "        for u in un:\n",
    "            for j in range(i, u):\n",
    "                gb.insert(i, [])\n",
    "            i = u + 1\n",
    "        for j in range(i, k[p]):\n",
    "            gb.append([])\n",
    "\n",
    "        L_prime[p] = gb\n",
    "    return L_prime\n",
    "\n",
    "\n",
    "def print_Lprime(L_prime):\n",
    "    for p in range(len(L_prime)):\n",
    "        print(p, L_prime[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "undefined-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- VARIABLES -------\n",
    "n_prime = 5\n",
    "\n",
    "# n is equal to the size of the treatmeant sample\n",
    "l = (np.array([5, 3, 5, 0, 0, 0, 0, 0]), np.array([4, 4, 5, 0, 0]))\n",
    "for li in l:\n",
    "    assert sum(li) == sum(l[0])\n",
    "# -----------------------\n",
    "\n",
    "P = len(l)\n",
    "L_prime = random_Lprime(P, n_prime, extract_k(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-writing",
   "metadata": {},
   "source": [
    "### Non-random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mechanical-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1.,  0., -0.,  0., -0.,  1.,  1., -0., -0., -0.,  0.,  1.]), 4.0)\n",
      "(array([ 1.,  0., -0.,  0., -0.,  1.,  1., -0., -0., -0.,  0.,  1.]), 4.0)\n",
      "(array([1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.]), 4.0)\n",
      "4\n",
      "4\n",
      "4.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "l = [[1, 0, 0, 2, 1], [3, 0, 1]]\n",
    "L_prime = [\n",
    "    [[0, 8, 10], [1, 2, 9], [3, 4], [5, 11], [6, 7]],\n",
    "    [[1, 3, 4, 6], [5, 9, 10, 8], [0, 2, 7, 11]],\n",
    "]\n",
    "\n",
    "print(min_imbalance_solver(l, L_prime))\n",
    "print(min_imbalance_solver_alt(l, L_prime))\n",
    "print(min_imbalance_solver_mcnf(l, L_prime))\n",
    "print(min_imbalance_solver_networkx(l, L_prime))\n",
    "print(min_imbalance_solver_google(l, L_prime))\n",
    "print(general_min_imbalance_solver_networkx(l, L_prime, 4))\n",
    "print(general_min_imbalance_solver_google(l, L_prime, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
